---
---

# Recurrent Neural Networks for time series

- An #RNN is a neural network that contains recurrent layers^[[2. W1 - Recurrent Neural Network]].
	- Designed for sequentially process sequences of `inputs`
	- They are able to process all time of sequences

### The recurrent layer

- A unique cell is used multiple times
	- The parameters are the same at each time step
![[Captura de Pantalla 2022-02-01 a la(s) 19.44.48.png]]

### Shape of the inputs in #RNN 

The RNN `input`
- Could be ==three dimensional==:
	1. Batch size ($m$)
	2. The number of time steps ($t$)
	3. The number of dimensions ($d$) at each time-step 
		1. The number of input features
```python
shape = [batch_size, n_time_steps, d_dims]
```

#### Example
*Univariate Series*
- Given a time series with $t = 30$ time steps, a batch size of $m = 4$ and one single feature ($d = 1$) the **full** `input` is three-dimensional ($m \times t \times d)$:
	- At *each time-step* the `input` will be `(4, 1)`
	- The `ouput` at *each time step* $\hat y$ will be $m \times a$, where $a$ is the number of neurons that the RNN cell has. In this example it has $3$, so the `output.shape` will be `(4, 3)`
- Thus, the **full** `output` will be three-dimensional too => ($(m \times t \times a)$ => `(4, 30, 3)`

![[Captura de Pantalla 2022-02-01 a la(s) 19.56.35.png]]

- ðŸ”´ <mark style='background-color: #FFA793 !important'>In a simple RNN</mark> the state $H_t$ is a copy of the previous output $y_{t-1}$

### Sequence-to-Vector RNN

- -> The #RNN only returns a single output:
	- The default behavior using #Keras

```python
model = keras.models.Sequential([
	# Return a sequence from the first RNN
	keras.layers.SimpleRNN(20, return_sequences = True,
						   input_sequence = [
							   # The dim related to the batch size is not required = `None`
							   None,  # Number of timesteps = `None` sequence of any length
							   1	  # Number of features per timestep
											]
						  ),
	# Return only the last value at time `t`
	keras.layers.SimpleRNN(20),
	# Use a dense layer with one neuron to perform Regression
	keras.layers.Dense(1)
])
```

![[Captura de Pantalla 2022-02-01 a la(s) 20.00.03.png]]

### Sequence-to-Sequence

- --> The #RNN returns a sequence

```python
model = keras.models.Sequential([
	# Return a sequence from the first RNN
	keras.layers.SimpleRNN(20, return_sequences = True,
						   input_sequence = [
							   # The dim related to the batch size is not required = `None`
							   None,  # Number of timesteps = `None` sequence of any length
							   1	  # Number of features per timestep
											]
						  ),
	# Return only the last value at time `t`
	keras.layers.SimpleRNN(20, return_sequences = True),
	# Use a dense layer with one neuron to perform Regression
	keras.layers.Dense(1)
])
```

![[Captura de Pantalla 2022-02-01 a la(s) 20.07.47.png]]