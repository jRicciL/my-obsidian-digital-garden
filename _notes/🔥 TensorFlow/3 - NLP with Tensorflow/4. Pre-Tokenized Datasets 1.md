---
---

# Pre-Tokenized Datasets

- The sequence of words can be just as important as their existence

## Tensorflow #datasets
### `tensorflow_datasets`
[[ðŸ“¦ Tensorflow-Datasets]]

### IMBD reviews dataset
==NOTE== The following only works with `Tensorflow 2`

```python
!pip install tensorflow==2.0.0-alpha0
```

- Get the IMBD dataset with `subwords` dataset -> `8k` version
```python
import tensorflow_datasets as tfds

imdb, info = tfds.load("imdb_reviews/subwords8k",
					  with_info = True,
					  as_supervised = True)
```

- get access to training and test data
```python
train_data, test_data = imbd['train'], imdb['test']
```

- Access to ==subwords tokenizer==
```python
tokenizer = info.features['text'].encoder
```

## Subwords Text Encoder
-> Deprecated:
- https://www.tensorflow.org/datasets/api_docs/python/tfds/deprecated/text/SubwordTextEncoder
-> about the deprecation:
- https://github.com/tensorflow/datasets/issues/2879

#### Inspect the vocabulary
```python
print(tokenizer.subwords)
```

- We can encode and decode specific strings
```python
sample_string = 'Tensorflow, from basics to mastery'

# Encode
tokenized_string = tokenizer.encode(sample_string)
# Decode
decoded_string = tokenizer.decode(tokenized_string)
```