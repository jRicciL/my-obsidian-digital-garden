---
---

# Debiasing word Embeddings

Some ideas to ==reduce== word embedding bias:
- Word embeddings **can reflect** gender, ethnicity, age, sexual orientation, and other ==biases== of the **text used to train the model**.
- There are different sense of bias:
	- Gender
	- Group stereotypes
	- Prejudice
	- Age
	- Sexual orientation
	
## Addressing bieas in word embeddings
1. **Identify bias direction:**
	- For a gender bias:
		- Subtract the corresponding word embeddings:
			- $e_{he} - e_{she}$
			- e_{male} - e_{female}$
			- ...
		- Average the differences and find the ==bias direction==
			- The bias direction can be a hyperplane
			- Can be obtained by #SingularValueDecomposition
				- Uses similar ideas such as [[Principal component Analisis]] (#PCA)
2. **Neutralization step:**
	- Get rid of bias => For every word that is not definitional, eg., that its meaning does not necessarily implies gender.
		- Example => 
			- `Doctor` and `Nurse`, **are not** definitional should not be biased to gender.
			- `Father` and `Mother` are definitional, as they imply gender
3. **Equalize pairs**:
	- Move a pair of biased words to be equally distanced to the concept/word desired.
		- `man` and `woman` to be equally distanced to `nurse`

### Which words are *definitional* and which are not?
- Authors trained a classifier to identify those words that are gender definitional such as:
	- Mother -> Father
	- Grandmother -> Grandfather

## Reference:
- [Bolukbasi, et al., 2016. Man is a computer programmer as woman is to homemaker? Debiasing word embeddings.](https://arxiv.org/abs/1607.06520)
