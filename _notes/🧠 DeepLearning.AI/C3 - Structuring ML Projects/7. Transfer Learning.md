---
---

# Transfer Learning
***

## Transfer Learning

#TransferLearning

- Take knowledge from one task to other task

## Definition
- Retrain the network to learn the last (or $k$ latest) layer of a pretrained Neural Network.
- Or add new layers to the pretrained network

![[Captura de Pantalla 2021-10-03 a la(s) 17.32.39.png]]

### When does Transfer Learning makes sense
Given the following two tasks:

```mermaid
graph LR
a(Task A) --> b(Task B)
```

1. Task A  and B have the same input $X$
2. Lots of data used for the pretrained network, but very low data for the new task.
	- ==Too much== data to pretrained the network (A)
	- ==Very few== data for the new network (B)
3. Low level features from A could be helpful for learning B.


## Multitask Learning
- *Loss* => Usual Logistic Loss but we have to sum across all labels
- *Unlink Softmax Regression* => Used instead classic softmax as we predict independently for each label.

### When does Multitask Learning makes sense
- Training on a set of tasks that could benefit from having shared lower-level features
- The amount of data for each task is quite similar
- When we can train a big enough neural network to do well on all the tasks
