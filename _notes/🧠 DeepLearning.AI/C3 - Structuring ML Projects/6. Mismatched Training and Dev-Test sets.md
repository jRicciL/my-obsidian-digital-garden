---
---

# Missmatched training and dev/test sets

- Deep learning algorithms have a huge hunger for training data.
	- They just often work best with enough data


1. **Ideally:**
	- `Training`, `dev` and `test` sets should come from the same distribution
	- But if there is not enough data resembling the true problem to solve this could be a disadvantage
	- ![[Captura de Pantalla 2021-09-29 a la(s) 20.52.46.png]]

2. <mark style='background-color: #9CE684 !important'>**The best option**</mark>
	- ðŸ”´  Focus on the `dev` and `test` sets:
		- They should have the same distribution
	- Then worry about the `trainig` set
	- Finally focus on improve the performance of the model reducing the overfitting
	
	
## Bias Variance with Missmatched Data Distributions
	
If the `training` and `dev` data come from the same distribution, but the `training` has lower error =>
	- There is a high variance problem
	
The other option is that they come from different distributions.

#### Use a `train+dev` set
- Thus we will have:
	- `training`
	- `training+dev`
	- `dev`
	- `test`

##### Variance Problem
Now, if the error of the `trainig+dev` >> `training`:
	- We will have a ==Variance problem==
	
![[Captura de Pantalla 2021-09-30 a la(s) 21.47.28.png]]

##### Data Missmatch problem
This occurs if errors:
- `trainig+dev`  â‰ƒ `training` (almost equal)
- But `trainig+dev`  and `training` << `dev`

This will suggest that the `training` and `dev` data come from different distributions

![[Captura de Pantalla 2021-09-30 a la(s) 21.53.30.png]]

- If you overfit the `dev` set => Get more `dev` set data

![[Captura de Pantalla 2021-09-30 a la(s) 22.00.01.png]]

## Addressing DataMissmatch
1. Carry out manual error analysis to try to understand difference between `training` and `dev/test` sets.
	a) `dev` could be very noisy
2. Try to collect more data similar between `training` and `dev` data
	1. Use ==Artificial Data Synthesis== -> But be careful of overfitting the noise