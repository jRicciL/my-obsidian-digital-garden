---
---

# Computer Vision

### Highlights
- A convolution extracts features from an input image by taking the dot product between the input data and a 3D array of weights (the filter).
- The 2D output of the convolution is called the ==feature map.== #FeatureMap
- A convolution layer is where the filter slides over the image and computes the dot product.
	- This transforms the input volume into an output volume of different size
- Zero padding helps keep more information at the image borders, and is helpful for building deeper networks, because you can build CONV layer without shrinking the height and width of the volumes.
- Pooling layers gradually reduce the height and width of the input by sliding 2D window over each specified region, then summarizing the features in that region

***

## Types of CV tasks
#ComputerVision

![[Quizzes#Computer vision]]

## Using Convolutions

<mark style='background-color: #FFA793 !important'>NOTE:</mark>
- Technically, the operation used in Deep Learning is not convolution but **_Cross-correlation_**
- True convolutions are commonly used in *signal processing*
	- Requires flipping the filter (2d filters) both vertically and horizontally

![[Captura de Pantalla 2021-10-27 a la(s) 19.08.26.png]]

### Edge detection example
- The ==convolution operation==
	- The earlier layers are focused on detecting edges and simple features
- Convolution involves the use of a ==filter== => ==kernel==
	- *Convolution Operation* is represented by the symbol $*$
	- In python:
		1. python: `conv_forward`
		2. tensorflow: `tf.nn.conv2d`
		3. keras: `Conv2D`

##### Sobel filter
- Puts more weight to the center cell
![[Captura de Pantalla 2021-10-15 a la(s) 8.17.27.png]]

##### Scharr filter
![[Captura de Pantalla 2021-10-15 a la(s) 8.17.43.png]]

## CNN ideas
- We can learn the filter parameters using #Backpropagation -> To detect better features
	- You can learn to detect edges in different angles
- With more layers, #CNN can learn more complicated features

![[Captura de Pantalla 2021-10-27 a la(s) 19.02.58.png]]

## Padding
- Given:
	- a $n \times n$ image (matrix)
	- a $f \times f$ filter (kernel)
- The output afeter convolution will be:
	- $n - f + 1 \times n - f + 1$ => `(n-f+1, n-f+1)`

- **==Padding==** =>
	- Using padding you can preserve the original size of the image after convolution
		- Commonly padding is done using `0`s

#### How much to pad?
<mark style='background-color: #FFA793 !important'>**Valid**</mark>
- *No padding* => 
	- Output size: $n - f + 1 \times n - f + 1$ => `(n-f+1, n-f+1)`

<mark style='background-color: #93EBFF !important'>**Same**</mark>
- *Pad* so that *output* size is the same as the *input* size =>
	- Output size: $n \times n$ => `(n, n)`

- By convention $f$ is always odd

![[Captura de Pantalla 2021-10-27 a la(s) 18.47.38.png]]

#### Main benefits of padding:
1. It allows to use a CONV layer without necessarily shrinking the height and width of the volumnes
	1. This is important for building deeper networks, since otherwise the height/width would shrink as we go deeper layers.
2. It helps to keep more information at the border of an image


## Stride Convolutions
- **==Stride==** => The size of the step
- The output using stride (just dive by $s$)
	- With a stride of size $2$ and a padding of size $p$:
		- $\left\lfloor\left(\frac{n + 2p -f}{s} + 1\right)\right\rfloor \times \left\lfloor\left(\frac{n + 2p -f}{s} + 1\right)\right\rfloor$

## Convolutions over volumes
#### Convolutions on RGB images

![[Captura de Pantalla 2021-10-27 a la(s) 19.14.19.png]]

- *`height`* * *`width`* * *`num. channels`*

- ðŸ”´ ==NOTE==: Commonly, with a $3D$ image we used a $3D$ filter but the ==output== will have a $2D$ dimensions.
	- Therefore, usually, the filter learns to detect features on one of the channels or on the three at the same time.
		- Still, the network learns all the parameters required.
	- That is why, increasing the number of channels does not directly increase the number of parameters when we use #keras 
- Therefore we need to use multiple filters to detect different features:
	
![[Captura de Pantalla 2021-10-27 a la(s) 19.20.17.png]]

## One layer of a Convolutional Neural Network
==Forward propagation==
Given an image with three color channels ($3D$ matrix):
- For each filter ($f\times f \times f$), at each layer, the network does the following:
	- Apply the filter  ($w^[l]$) =>
		- Which gives a $2\times 2$ matrix
	- Sum a bias $b$
		- The bias is broadcaster to all cells
	- Apply the activation function 
	- Stack the resulting $2\times 2$ matrices => which gives $a^[l]$ = $3D$ matrix if there are more than one filter

![[Captura de Pantalla 2021-10-27 a la(s) 19.33.14.png]]


#### On the notation
If layer $l$ is a convolution layer:
- $f^l$ = filter size
- $p^l$ = padding
- $s^l$ = stride
- *Input* shape (layer $l - 1$):  
	- $n_{hight}^{l-1} \times n_{width}^{l-1} \times n_{channels}^{l-1}$
- *Output* shape (layer $l$): 
	- $n_{hight}^{l} \times n_{width}^{l} \times n_{channels}^{l}$

The dimensions of layer $l$ depend of the dimensions of the previous layer and the number of filters, padding, and stride used:
- Dims. of layer $l$ (==output==) -> For the width ($n_{width}^{l}$) and height ($n_{hight}^{l}$):
	- $$n^{[l]} =  \left\lfloor\frac{n^l + 2p^l -f^l}{s^l} + 1\right\rfloor$$

- Dims of each ==filter== ($f^l$) of layer $l$:
	- $f^l \times f^l \times n_c^{l - 1}$
	- The third dimension matches the number of filters from the previous layer => $[l-1]$
	- Each of the two first dimensions is $f^l$, assuming a squared filter

- Activations:
	- The same shape as the outputs:
		- $a^l \rightarrow n_H^l \times n_W^l \times n_c^l$
		- $A^l = m \times a^l$
			- $m$ examples times the activation
- Weights:
	- $f^l \times f^l \times n_c^{l-1} \times n_c^l$
	- Where $n_c^l$ is the number of filters selected for the current layer
		- In #Keras this is the `filters` parameter
		- 
![[Captura de Pantalla 2021-11-10 a la(s) 20.38.37.png]]

## Simple Convolutional Neural Network example
![[Captura de Pantalla 2021-11-10 a la(s) 20.53.40.png]]

## Pooling Layers
#pooling 
- non learneable layers
- Commonly they are not reported as layers
	- Because researches report only those layers that have weights

- ==Max Pooling==:
	- It employs the `filter_size` and `stride` hyperparameters
		- `padding` is rarely used
	- Keeps the maximum value per window
	- *It has no parameters to learn*
	- The *pooling* computation is performed independently for each channel
		- The number of channels is preserved

- Average Pooling:
	- Take the average
	- It is less used than max pooling
	- In very deep networks Average Pooling is used to colapse the results from the last Conv layer

## Why convolutions?
##### Parameter sharing:
- A feature detector that is useful in one part of the image is probably useful in another part of the image

##### Sparsity of connections
- In each layer, each output value depends only on a small number of inputs.
	- This differs from Full connected networks, where each unit of layer $l$ is connected with all units from layer $l-1$