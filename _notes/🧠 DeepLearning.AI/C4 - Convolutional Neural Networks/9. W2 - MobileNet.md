---
---

# MobileNets

## Motivation for MobileNets
- Low computational cost at **deployment**
	- Howard et al. 2007, MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
- Around 10 times cheaper
- Useful for mobile and embedded vision applications
- Key idea:
	- Normal vs ==depthwise-separable convolutions==
	- Modifies the convolution operation

### Normal vs MobileNet convolutions

#### Normal convolutions
Computation cost

![[Captura de Pantalla 2021-11-23 a la(s) 20.24.32.png]]

#### Depthwise-separable convolution
![[Captura de Pantalla 2021-11-23 a la(s) 20.33.18.png]]
##### Depthwise part
- Use the same number of filters as of that of the input layer = $n_c$
	- Apply each filter per channel -> no over all input channels
![[Captura de Pantalla 2021-11-23 a la(s) 20.28.51.png]]

- As a result we got the same number of channels in layer $l$ and in layer $l+1$
	- The second part, ==separable==, will use `1x1` convolutions to increase the number of channels.

##### Separable part => ==Pointwise convolution==
#PointwiseConvolution
- This part increases the number of channels $n_c'$ by using `1x1` convolutions
![[Captura de Pantalla 2021-11-23 a la(s) 20.32.54.png]]


***
# MobileNet architecture

#### MobileNet v1
- It uses ==Depthwise-pointwise convolutions==

![[Captura de Pantalla 2021-11-24 a la(s) 18.15.27.png]]


#### MobileNet v2
- It uses a ==Residual connection== -> [[6. W2 - ResNets]]
- It uses an <mark style='background-color: #93EBFF !important'> Expansion layer</mark>
	- a `1x1` convolution that expands the number of channels
- It uses a bootleneck block

![[Captura de Pantalla 2021-11-24 a la(s) 18.18.39.png]]

##### The bottleneck block
- This block is repeated 17 times



