---
---

# Transfer Learning with MobileNet
#Assignment
***
### Key points to remember
- When calling `image_data_set_from_directory()` specify the train/validation subsets and match the seeds to prevent overlap
- Use `prefetch` to prevent memory bottlenecks when reading from disk
- Give your model more to learn form with simple data augmentation like rotation and flipping
- When using a pretrained model, it's best to reuse weights it was trained on.

*** 
- We will use [[9. W2 - MobileNet]] which was pretrained on ImageNet
	- It's been pre-trained on ImageNet, a dataset containing over 14 million images and 1000 classes.

By the end of this assignment, you will be able to:

- Create a dataset from a directory
- Preprocess and augment data using the Sequential API
- Adapt a pretrained model to new data and train a classifier using the Functional API and MobileNet
- Fine-tune a classifier's final layers to improve accuracy 

### Packages

```python
import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
import tensorflow.keras.layers as tfl

from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation

```

### Create the Dataset and Split it into Training and Validation Sets

When training and evaluating deep learning models in #Keras.
- Generating a dataset from image files stored on disk is simple and fast.
- Call `image_data_set_from_directory()` to read from the directory and create both training and validation datasets.
- If you are specifying a validation split, you will also need to specify the subset for each portion.
	- Just set the training set to `subset = 'training'` and the validation set to `subset = 'validation'`

- `image_dataset_from_directory()`

- ==Note==: 
	- You'll also set your seeds to match each other, so your training and validation sets don't overlap. :) `

```python
BATCH_SIZE = 32
IMG_SIZE = (160, 160)
directory = "dataset/"
train_dataset = image_dataset_from_directory(directory,
                                             shuffle=True,
                                             batch_size=BATCH_SIZE,
                                             image_size=IMG_SIZE,
                                             validation_split=0.2,
                                             subset='training',
                                             seed=42)
validation_dataset = image_dataset_from_directory(directory,
                                             shuffle=True,
                                             batch_size=BATCH_SIZE,
                                             image_size=IMG_SIZE,
                                             validation_split=0.2,
                                             subset='validation',
                                             seed=42)
```

### Preprocess and Augment Training data

- `data.prefetch`:
	- `prefetch()` prevents a memory bottleneck that can occur when reading from disk.
	- It sets aside some data and keeps it ready for when it's needed, by creating a source dataset from your input data, applying a tranformation to preprocess it, then iterating over the dataset one element at time.
	- Because the iteration is traming, the data does not need to fit in memory.
	- You can use `tf.data.experimental.AUTOTUNE` to choose the parameters automatically. => This turns the parameter dynamically at runtime.
		- It uses a optimization algorithm that tries to fit the best allocation of its CPU budget across all  tunable operations

```python
AUTOTUNE = tf.data.experimental.AUTOTUNE
train_dataset = train_dataset.prefetch(buffer_size = AUTOTUNE)
```

```python
preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input
```

#### Data Augmentation
- `RandomFlip`
- `RandomRotation`

```python
def data_augmenter():
    '''
    Create a Sequential model composed of 2 layers
    Returns:
        tf.keras.Sequential
    '''
    ### START CODE HERE
    data_augmentation = tf.keras.Sequential()
    data_augmentation.add(RandomFlip('horizontal'))
    data_augmentation.add(RandomRotation(0.2))
    ### END CODE HERE
    
    return data_augmentation
```


## Using MobileNet for Transfer Learning
[[Transfer Learning]][[7. Transfer Learning]]

- MobileNet was trained on #ImageNet and is optimized to run on mobile an other low-power applications.
- It's 155 layers deep
- Very efficient for object detection and image segmentation tasks as well as classification tasks

**What you should remember**:

* MobileNetV2's unique features are: 
  * Depthwise separable convolutions that provide lightweight feature filtering and creation
  * Input and output bottlenecks that preserve important information on either end of the block
* Depthwise separable convolutions deal with both spatial and depth (number of channels) dimensions

##### MobileNet Architecture
- Take a look at [[9. W2 - MobileNet]]
	- It uses Depthwise separable convolutions
	- Thin input and output bottlenecks between layers
	- Shortcut connections between bottleneck layers
	
==MobileNetV2== uses depthwise separable convolutions as efficient building blocks. Traditional convolutions are often very resource-intensive, and  depthwise separable convolutions are able to reduce the number of trainable parameters and operations and also speed up convolutions in two steps: 

1. The first step calculates an intermediate result by *convolving on each of the channels independently*. This is the depthwise convolution.

2. In the second step, *another convolution merges the outputs of the previous step* into one. This gets a single result from a single feature at a time, and then is applied to all the filters in the output layer. This is the ==pointwise convolution==, or: **Shape of the depthwise convolution X Number of filters.**

![[mobilenetv2.png]]

Each block consists of an inverted residual structure with a bottleneck at each end.
These bottlenecks encode the intermediate inputs and outputs in a low dimensional space, and prevent non-linearities from destroying important information.

- The shortcut connections, which are similar to the ones in traditional residual networks, aerve the same purpose of speeding up training and improving predictions.
- These connections skip over the intermediate convolutions and connect the bottleneck layers

#### Load pretrained weights
- load weights from `imagenet` using `MobileNetV2`
```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=True,
                                               weights='imagenet')
```

#### Make predictions with MobileNet
- ==NOTE==: At this point we are using `Mobilenet` without uising it for transfer learning
- Choose the first batch from the tensorflow dataset to use the images, and run it through the MobileNetV2 base model to test out the predictions on some of your images. 

```python
image_batch, label_batch = next(iter(train_dataset))
feature_batch = base_model(image_batch)
print(feature_batch.shape)
```

Now decode the predictions made by the model. Earlier, when you printed the shape of the batch, it would have returned (32, 1000). The number 32 refers to the batch size and 1000 refers to the 1000 classes the model was pretrained on. The predictions returned by the base model below follow this format:

First the class number, then a human-readable label, and last the probability of the image belonging to that class. You'll notice that there are two of these returned for each image in the batch - these the top two probabilities returned for that image.

```python
base_model.trainable = False
image_var = tf.Variable(image_batch)
pred = base_model(image_var)

tf.keras.applications.mobilenet_v2.decode_predictions(pred.numpy(), top=2)
```

## Layer freezing with the functional API

In the next sections, you'll see how you can use a pretrained model to modify the classifier task so that it's able to recognize alpacas. You can achieve this in three steps: 

1. Delete the top layer (the classification layer)
    * Set `include_top` in `base_model` as False
2. Add a new classifier layer
    * Train only one layer by freezing the rest of the network
    * As mentioned before, a single neuron is enough to solve a binary classification problem.
3. Freeze the base model and train the newly-created classifier layer
    * Set `base model.trainable=False` to avoid changing the weights and train *only* the new layer
    * Set training in `base_model` to False to avoid keeping track of statistics in the batch norm layer

```python
# UNQ_C2
# GRADED FUNCTION
def alpaca_model(image_shape=IMG_SIZE, data_augmentation=data_augmenter()):
    ''' Define a tf.keras model for binary classification out of the MobileNetV2 model
    Arguments:
        image_shape -- Image width and height
        data_augmentation -- data augmentation function
    Returns:
    Returns:
        tf.keras.model
    '''
    
    
    input_shape = image_shape + (3,)
    
    ###Â START CODE HERE
    
    base_model = tf.keras.applications.MobileNetV2(input_shape = input_shape,
                                                   include_top = False, # <== Important!!!!
                                                   weights='imagenet') # From imageNet
    
    # freeze the base model by making it non trainable
    base_model.trainable = False 

    # create the input layer (Same as the imageNetv2 input size)
    inputs = tf.keras.Input(input_shape) 
    
    # apply data augmentation to the inputs
    x = data_augmenter()(inputs)
    
    # data preprocessing using the same weights the model was trained on
    x = preprocess_input(x) 
    
    # set training to False to avoid keeping track of statistics in the batch norm layer
    x = base_model(x, training=False) 
    
    # add the new Binary classification layers
    # use global avg pooling to summarize the info in each channel
    x = tfl.GlobalAveragePooling2D()(x) 
    # include dropout with probability of 0.2 to avoid overfitting
    x = tfl.Dropout(0.2)(x)
        
    # use a prediction layer with one neuron (as a binary classifier only needs one)
    outputs = tfl.Dense(1, activation = 'linear')(x)
    
    ###Â END CODE HERE
    
    model = tf.keras.Model(inputs, outputs)
    
    return model
```

```python
base_learning_rate = 0.001
model2.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
```


## Fine-tuning the Model
- Fine tuning implies rerunning the trainingphase in the last layers to improve the performance.
- It often requires to use a ==smaller learning rate==
- Take smaller steps to adapt it a little more closely to the new data.	
	- This is done by unfreezing the layers at the end of the network
	- Then retrain hte model on the final layers with a very low learning rate.
- The intuition:
	- For transfer learning the low-level features can be kept the same
	- When add new data for transfer learning, what you want is the high-level features to adapt to it.
	- This is rather like letting the network learn to detect features more related to the data

> The important takeaway is that the later layers are the part of your network that contain the fine details (pointy ears, hairy tails) that are more specific to your problem.

```python
# UNQ_C3
base_model = model2.layers[4]
base_model.trainable = True
# Let's take a look to see how many layers are in the base model
print("Number of layers in the base model: ", len(base_model.layers))

# Fine-tune from this layer onwards
fine_tune_at = 120

###Â START CODE HERE

# Freeze all the layers before the `fine_tune_at` layer
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False
    
# Define a BinaryCrossentropy loss function. Use from_logits=True
loss_function= tf.keras.losses.BinaryCrossentropy(from_logits = True)
# Define an Adam optimizer with a learning rate of 0.1 * base_learning_rate
optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1 * base_learning_rate)
# Use accuracy as evaluation metric
metrics=['accuracy']

###Â END CODE HERE

model2.compile(loss=loss_function,
              optimizer = optimizer,
              metrics=metrics)
```