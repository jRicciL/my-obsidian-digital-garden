---
---

# CNN - Tensorflow
#Tensorflow #keras 
#Assignment
- Create a classifier using TF Keras Sequential API
- Build a ConvNet to identify sing language digits using the TF Keras Functional API

<a name='1'></a>
## 1 - Packages

As usual, begin by loading in the packages.
```python
import math
import numpy as np
import h5py
import matplotlib.pyplot as plt
from matplotlib.pyplot import imread
import scipy
from PIL import Image
import pandas as pd
import tensorflow as tf
import tensorflow.keras.layers as tfl
from tensorflow.python.framework import ops
from cnn_utils import *
from test_utils import summary, comparator

%matplotlib inline
np.random.seed(1)
```

## load the Data and split the data into train/test sets

```python
X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_happy_dataset()

# Normalize image vectors
X_train = X_train_orig/255.
X_test = X_test_orig/255.

# Reshape
Y_train = Y_train_orig.T
Y_test = Y_test_orig.T

print ("number of training examples = " + str(X_train.shape[0]))
print ("number of test examples = " + str(X_test.shape[0]))
print ("X_train shape: " + str(X_train.shape))
print ("Y_train shape: " + str(Y_train.shape))
print ("X_test shape: " + str(X_test.shape))
print ("Y_test shape: " + str(Y_test.shape))
```

# The Sequential API

- The Keras Sequential API can be used to build simple models with layer operations that proceed in a sequential order.
- Layers can be incrementally added to the `Sequential` model using `.add()`
- If your model is non-linear or contains layers with multiple inputs or outputs, a `Sequential` model wouldn't be the right choice!

### Exercise 1: The `happyModel`
Also, plug in the following parameters for all the steps:

 - [ZeroPadding2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D): padding 3, input shape 64 x 64 x 3
 - [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D): Use 32 7x7 filters, stride 1
 - [BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization): for axis 3
 - [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU)
 - [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D): Using default parameters
 - [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) the previous output.
 - Fully-connected ([Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) layer: Apply a fully connected layer with 1 neuron and a sigmoid activation. 
 
 
 **Hint:**
 
 Use **tfl** as shorthand for **tensorflow.keras.layers**
 
 ```python
model = tf.keras.Sequential([
	tfl.Input((64, 64, 3)),
	## ZeroPadding2D with padding 3, input shape of 64 x 64 x 3
	tfl.ZeroPadding2D(3),
	## Conv2D with 32 7x7 filters and stride of 1
	tfl.Conv2D(filters = 32, 
			   kernel_size = (7, 7), strides = (1,1)),
	## BatchNormalization for axis 3
	tfl.BatchNormalization(axis = 3),
	## ReLU
	tfl.ReLU(),
	## Max Pooling 2D with default parameters
	tfl.MaxPool2D(),
	## Flatten layer
	tfl.Flatten(),
	## Dense layer with 1 unit for output & 'sigmoid' activation
	tfl.Dense(1, activation = 'sigmoid')
])
```

#### Compile the model

```python
happy_model.compile(optimizer='adam',
                   loss='binary_crossentropy',
                   metrics=['accuracy'])
```

```python
happy_model.summary()
```

```
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
zero_padding2d (ZeroPadding2 (None, 70, 70, 3)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 64, 64, 32)        4736      
_________________________________________________________________
batch_normalization (BatchNo (None, 64, 64, 32)        128       
_________________________________________________________________
re_lu (ReLU)                 (None, 64, 64, 32)        0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
dense (Dense)                (None, 1)                 32769     
=================================================================
Total params: 37,633
Trainable params: 37,569
Non-trainable params: 64
_________________________________________________________________
```

#### Train an Evaluate the Model

```python
happy_model.fit(X_train, Y_train, epochs=10, batch_size=16)
```

```
Epoch 1/10
38/38 [==============================] - 4s 100ms/step - loss: 0.8370 - accuracy: 0.7100
Epoch 2/10
38/38 [==============================] - 4s 92ms/step - loss: 0.2160 - accuracy: 0.9167
Epoch 3/10
38/38 [==============================] - 4s 95ms/step - loss: 0.1557 - accuracy: 0.9350
Epoch 4/10
38/38 [==============================] - 4s 95ms/step - loss: 0.1406 - accuracy: 0.9417
Epoch 5/10
38/38 [==============================] - 4s 95ms/step - loss: 0.1037 - accuracy: 0.9600
Epoch 6/10
38/38 [==============================] - 4s 97ms/step - loss: 0.0911 - accuracy: 0.9717
Epoch 7/10
38/38 [==============================] - 4s 95ms/step - loss: 0.0661 - accuracy: 0.9733
Epoch 8/10
38/38 [==============================] - 4s 95ms/step - loss: 0.0645 - accuracy: 0.9850
Epoch 9/10
38/38 [==============================] - 4s 97ms/step - loss: 0.0549 - accuracy: 0.9817
Epoch 10/10
38/38 [==============================] - 4s 95ms/step - loss: 0.0760 - accuracy: 0.9667
```

```python
happy_model.evaluate(X_test, Y_test)
```

## The Functional API
#KerasFunctionalAPI

#### The Functional API
- The Functional API can handle models with:
	- Non-linear topology.
	- Shared layers.
	- Layers with multiple inputs and outputs.
	- Skip connections are possible

### The SINGS dataset
#SingsDataset

<img src="https://img-blog.csdnimg.cn/20181205231906317.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIxNTc4ODQ5,size_16,color_FFFFFF,t_70">

The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of `index` below and re-run to see different examples. 

```python
# Loading the data (signs)
X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_signs_dataset()
```

#### Split the data
```python
X_train = X_train_orig/255.
X_test = X_test_orig/255.
Y_train = convert_to_one_hot(Y_train_orig, 6).T
Y_test = convert_to_one_hot(Y_test_orig, 6).T
print ("number of training examples = " + str(X_train.shape[0]))
print ("number of test examples = " + str(X_test.shape[0]))
print ("X_train shape: " + str(X_train.shape))
print ("Y_train shape: " + str(Y_train.shape))
print ("X_test shape: " + str(X_test.shape))
print ("Y_test shape: " + str(Y_test.shape))
```

### Forward propagation

Begin building your graph of layers by creating an input node that functions as a callable object:

- **input_img = tf.keras.Input(shape=input_shape):** 

Then, create a new node in the graph of layers by calling a layer on the `input_img` object: 

- **tf.keras.layers.Conv2D(filters= ... , kernel_size= ... , padding='same')(input_img):** Read the full documentation on [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D).

- **tf.keras.layers.MaxPool2D(pool_size=(f, f), strides=(s, s), padding='same'):** `MaxPool2D()` downsamples your input using a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window.  For max pooling, you usually operate on a single example at a time and a single channel at a time. Read the full documentation on [MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D).

- **tf.keras.layers.ReLU():** computes the elementwise ReLU of Z (which can be any shape). You can read the full documentation on [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU).

- **tf.keras.layers.Flatten()**: given a tensor "P", this function takes each training (or test) example in the batch and flattens it into a 1D vector.  

    * If a tensor P has the shape (batch_size,h,w,c), it returns a flattened tensor with shape (batch_size, k), where $k=h \times w \times c$.  "k" equals the product of all the dimension sizes other than the first dimension.
    
    * For example, given a tensor with dimensions [100, 2, 3, 4], it flattens the tensor to be of shape [100, 24], where 24 = 2 * 3 * 4.  You can read the full documentation on [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten).

- **tf.keras.layers.Dense(units= ... , activation='softmax')(F):** given the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation on [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense).

In the last function above (`tf.keras.layers.Dense()`), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters.

#### Model definition
```python
# GRADED FUNCTION: convolutional_model

def convolutional_model(input_shape):
    """
    Implements the forward propagation for the model:
    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> DENSE
    
    Note that for simplicity and grading purposes, you'll hard-code some values
    such as the stride and kernel (filter) sizes. 
    Normally, functions should take these values as function parameters.
    
    Arguments:
    input_img -- input dataset, of shape (input_shape)

    Returns:
    model -- TF Keras model (object containing the information for the entire training process) 
    """

    input_img = tf.keras.Input(shape=input_shape)
    ## CONV2D: 8 filters 4x4, stride of 1, padding 'SAME'
    Z1 = tfl.Conv2D(filters = 8, 
                    kernel_size = (4,4), 
                    strides = 1, padding = 'same')(input_img)
    ## RELU
    A1 = tfl.ReLU()(Z1)
    ## MAXPOOL: window 8x8, stride 8, padding 'SAME'
    P1 = tfl.MaxPool2D(pool_size = (8,8), 
                       strides = 8, 
                       padding = 'same')(A1)
    ## CONV2D: 16 filters 2x2, stride 1, padding 'SAME'
    Z2 = tfl.Conv2D(filters = 16, 
                    kernel_size = (2,2), 
                    strides = (1,1), 
                    padding = 'same')(P1)
    ## RELU
    A2 = tfl.ReLU()(Z2)
    ## MAXPOOL: window 4x4, stride 4, padding 'SAME'
    P2 = tfl.MaxPool2D(pool_size = (4,4),
                       strides = (4,4),
                       padding = 'same')(A2)
    ## FLATTEN
    F = tfl.Flatten()(P2)
    ## Dense layer
    ## 6 neurons in output layer. Hint: one of the arguments should be "activation='softmax'" 
    outputs = tfl.Dense(units = 6, activation = 'softmax')(F)
    model = tf.keras.Model(inputs=input_img, outputs=outputs)
    return model
```


#### Train the model

```python
train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(64)
test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(64)
history = conv_model.fit(train_dataset, epochs=100, validation_data=test_dataset)
```

```
Epoch 1/100
17/17 [==============================] - 2s 113ms/step - loss: 1.8089 - accuracy: 0.1889 - val_loss: 1.7837 - val_accuracy: 0.2000
Epoch 2/100
17/17 [==============================] - 2s 106ms/step - loss: 1.7797 - accuracy: 0.2269 - val_loss: 1.7769 - val_accuracy: 0.1833
Epoch 3/100
```