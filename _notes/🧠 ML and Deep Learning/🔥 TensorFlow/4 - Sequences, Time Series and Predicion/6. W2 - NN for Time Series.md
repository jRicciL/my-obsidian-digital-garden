---
---

# Deep Neural Networks for Time Series

#TimeSeries #WindowedDatasets

***

## Preparing Features and labels

```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
```

- Divide the date into features $X$ and labels $y$
	- $X$ a window $w$ of values of the time series ranging from $t$ to $t+w$
	- $y$ the next value $t + w + 1$
	- So we will take a window of the data and train an #DNN model to predict the next value

```python
# Create a simple time series
dataset = tf.data.Dataset.range(10)

# Create a sliding window of size 5 and stride = 1
dataset = dataset.window(5, shift = 1,
						 # Truncate those windows with less than 5 values
						 # which are the last windows
						drop_remainder = True)

# Iterate over the windows of the dataset
for window_dataset in dataset:
	for val in window_dataset:
		print(val.numpy(), end = " ")
	print()
```

## Create the `train`/`test` datasets
We will split the time series into a set of $x$ and $y$ values using the `.window()` method.
- We will also shuffle the position of ($x$, $y$) pair values:

```python
# Create the `dataset` time series
dataset = tf.data.Dataset.range(10)
# Create the windows
w = 5
dataset = dataset.window(w, 
						 shift = 1, 
						 drop_remainder = True)
# Use a map function to capture the w - 1 values as X
# and the last value as y
dataset = dataset.flat_map(
	lambda window: (window[:-1], window[-1:])
)

# Shuffle the list of pair values (x, y)
dataset = dataset.shuffle(
				buffer_size = 10
			)

# Batch the data
dataset = dataset.batch(2).prefetch(1)

# Iterate over the values of the dataset
for x, y in dataset:
	print('x = ', x.numpy())
	print('y = ', y.numpy())
```

![[Captura de Pantalla 2022-01-06 a la(s) 18.22.38.png]]

<mark style='background-color: #FFA793 !important'>ðŸ”´ About Sequence Bias:</mark>
- *Sequence bias is when the order of things can impaxt the selection of things*
- When training data in a dataset, we don't want the sequence to impact the training biasing because of the order of the elements.
	- So it is good to ==shuffle them up==
		- `dataset.shuffle(buffer_size = 10)`

### Step by step
- The following notebook shows the above procedure step by step.

<a href="https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/adding_C4/C4/W2/ungraded_labs/C4_W2_Lab_1_features_and_labels.ipynb" target="_parent">
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

## Feeding windowed dataset into neural network

![[Captura de Pantalla 2022-01-06 a la(s) 19.12.47.png]]

### Windowed Dataset ( #WindowedDatasets )

We will implement the following function:
1. ==Create== the dataset using `from_tensor_slices()` method
2. ==Window== the dataset, the `window_size` parameter, will determine the size of the `X` variable.
3. ==Flat== the dataset to make it easier to work with;
	- Flat it into chuncks in the size of the `window_size + 1`.
		- The last value will correspond to the target value $y$
4. ==Shuffle== the data and use a `shuffle_buffer` to speed the process
5. Get the ==features== and ==labels== of each chunk of data into a tuple of $X$ and $y$ values

```python
def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
	# Create the dataset from the `series` 
	dataset = tf.data.Dataset.from_tensor_slices(
				series)
	# Create the windows:
	# add 1 to w, to match |X| = w
	dataset = dataset.window(
		window_size + 1, shift = 1, drop_remainder = True	
	)
	# Flat the data
	dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))
	# Shuffle the dataset
	dataset = dataset.shuffle(shuffle_buffer).
					 .map(lambda window: 
						 	(window[:-1], window[-1]))
	# Create into `X` and `y`
	dataset = dataset.batch(batch_size).prefetch(1)
	
	return dataset
	
```

## Single layer Neural Network

### Linear Regression

##### Split the initial data into `train` and `validation`

```python
# Train
split_time = 1000
time_train = time[:split_time]
x_train    = series[:split_time]

# Test
time_test = time[split_time:]
x_valid   = series[split_time:]
```

##### Create the dataset: `X` and `y`
```python
window_size = 20
batch_size  = 32
shuffle_buffer_size = 1000

dataset = windowed_dataset(
	series, window_size, batch_size, shuffle_buffer_size
)
```

##### Define the LR model (a perceptron)
```python
# Defiene the NN layer
l0  = tf.keras.layers.Dense(1, input_shape = [window_size])
model = tf.keras.models.Sequential([l0])

# Compile the model
model.compile(
	# Use Mean Square Error as the loss function
	loss = 'mse',
	optimizer = tf.keras.optimizers.SDG(
		lr = 1e-6, momentum = 0.9
	)
)

# Train the model
model.fit(
	dataset, epochs = 100, verbose = 0
)
```

##### Inspect the weight values
```python
print("Layer weights {}".format(l0.get_weights()))
```

#### Prediction

##### Predict a single value
![[Captura de Pantalla 2022-01-06 a la(s) 20.14.22.png]]

```python
print(series[1:21])

model.predict(
	series[1:21][np.newaxis]
	# np.newaxis reshape the series[1:21] array
	# to feed into the model
)
```

##### Forecast the Series values using the model

```python
forecast = []

for time in range(len(series) - window_size):
	# Iterate over the series and predict over each window
	forecast.append(
		model.predict(
			series[time:time + window_size][np.newaxis]
		)
	)
	
forecast = forecast[split_time - window_size: ]
results = np.array(forecast)[:, 0, 0]
```

![[Captura de Pantalla 2022-01-06 a la(s) 20.21.20.png]]
- ðŸ”µ Observed values 
- ðŸŸ  Predicted values

##### Evaluate the predictions

```python
tf.keras.metrics.mean_absolute_error(
	x_valid, results.numpy()
)
```


## Deep Neural Network

![[Pasted image 20220106211028.png]]

### Training, tuning, and prediction

##### Define the NN model
A #NN with three layers:
- Create the dataset
```python
window_size = 20
batch_size  = 32
shuffle_buffer_size = 1000

dataset = windowed_dataset(
	series, window_size, batch_size, shuffle_buffer_size
)
```

- Create the model
```python
model = tf.keras.models.Sequential([
	tf.keras.layers.Dense(10, input_shape = [window_size], activation = 'relu'),
	tf.keras.layers.Dense(10, activation = 'relu'),
	tf.keras.layers.Dense(1)
])

model.compile(loss = 'mse', 
			  optimizer = tf.keras.optimizers.SGD(lr = 1e-6, 
												  momentum = 0.9))

model.fit(dataset, epochs = 1000, verbose = 0)
```

##### Use a `LearningRateScheduler` to tune the learning rate value
- Optimize the #learning-rate value:
	- We can find the optimal value of the `learning_rate` by modifying the `lr` at each epoch using a `Callback`
1. Define the `callback` function
```python
from tensorflow.keras.callbacks import LearningRateScheduler

# Set the callback
lr_schedule = LearningRateSchedurle(
	lambda epoch: 1e-8 * 10**(epoch / 20)
)
```

2. Compile and fit the model and use the `callback` defined above
```python
optimizer = tf.keras.optimizers.SDG(lr = 1e-8, momentum=0.9)

model.compile(loss = 'mse', optimizer = optimizer)
history = model.fit(dataset, epochs = 100, 
					# Use the callback
				   callbacks = [lr_schedule])
```

3. Evaluate the ==loss== of the model and find the optimal value of `learning_rate`
	1. Create a plot to evaluate the loss per epoch against the #learning-rate per epoch used
	2. Pick the lowest point of the curve while it is still relatively stable
```python
lrs = 1e-8 * (10 ** (np.arrange(100) / 20))
```

4. Use the found #learning-rate to train the final model.
```python
# Assume the best value was 7e-6
optimizer = tf.keras.optimizers.SDG(lr = 7e-6, momentum=0.9)

model.compile(loss = 'mse', optimizer = optimizer)
history = model.fit(dataset, epochs = 500) # We don't require the callback any more
```