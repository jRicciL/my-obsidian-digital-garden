# **Apache Spark Programming**
### About the course

- https://customer-academy.databricks.com/learn/course/63/play/13454/about-this-course;lp=160
**Welcome to Apache Spark ProgrammingTM with Databricks!**  
In this course, you will explore the fundamentals of Apache Spark and Delta Lake on Databricks. You will learn the architectural components of Spark, the DataFrame and Structured Streaming APIs, and how Delta Lake can improve your data pipelines. Lastly, you will execute streaming queries to process streaming data and understand the advantages of using Delta Lake.

This course helps to prepare you for the Databricks Certified Associate Developer for Apache Spark exam.

**Course goals**  
By the end of our time together, you’ll be able to:

- Define Spark’s architectural components.
- Describe how DataFrames are transformed, executed, and optimized in Spark.
- Apply the DataFrame API to explore, preprocess, join, and ingest data in Spark
- Apply the Structured Streaming API to perform analysis on streaming data
- Use Delta Lake to improve the quality and performance of data pipelines


# Advanced pandas

- [https://customer-academy.databricks.com/learn/course/1211/play/7275/advanced-pandas;lp=160](https://customer-academy.databricks.com/learn/course/1211/play/7275/advanced-pandas;lp=160)
- Format issue for paths of dbfs
    - `.replace(”dbfs:”, “/dbfs”)`
    - remove file if already exists
        - `dbutils.fs.rm(write_path)`

# Pandas API on Spark

- Pandas only works on a single machine
- We can use the pandas-like syntax getting the performance of Saork
- Usariamos Spark no por temas de memoria, sino por temas de tiempo de ejecuci’on

# Spark DataFrames

## DataFrame Transformations

- DataFrame **transformations** are methods that return a new DataFrame and are **lazily evaluated**
    
    ```sql
    df.select("id", "result")
    	.where("result > 70")
    	.orderBy("result")
    ```
    
- DataFrame Actions ⇒ Are methods that trigger computation
    
    ```sql
    df.count()
    df.collect() 
    df.show() # Displays the top few rows
    ```
    
- An Action is needed to trigger the execution of any DataFrame Transformations
    

## Aggregations

- `GroupBy` returns a Grouped data object in python
    
    ```python
    df.groupBy("column").
    	.agg(), .avg(), .count(), .max(), .mean(), min(), .pivot(). sum()
    ```
    
